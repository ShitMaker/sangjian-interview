## Java基础

### Vector,ArrayList, LinkedList的区别是什么？

答：

1. Vector、ArrayList都是以类似数组的形式存储在内存中，LinkedList则以链表的形式进行存储。

2. List中的元素有序、允许有重复的元素，Set中的元素无序、不允许有重复元素。

3. Vector线程同步，ArrayList、LinkedList线程不同步。

4. LinkedList适合指定位置插入、删除操作，不适合查找；ArrayList、Vector适合查找，不适合指定位置的插入、删除操作。

5. ArrayList在元素填满容器时会自动扩充容器大小的50%，而Vector则是100%，因此ArrayList更节省空间。

### HashTable, HashMap，TreeMap区别？

答：

1. HashTable线程同步，HashMap非线程同步。

2. HashTable不允许<键,值>有空值，HashMap允许<键,值>有空值。

3. HashTable使用Enumeration，HashMap使用Iterator。

4. HashTable中hash数组的默认大小是11，增加方式的old*2+1，HashMap中hash数组的默认大小是16，增长方式一定是2的指数倍。

5. TreeMap能够把它保存的记录根据键排序，默认是按升序排序。

## Java并发
### 怎么提高并发量，请列举你所知道的方案？
### 系统的用户量有多少？多用户并发访问时如何解决？

### 说说阻塞队列的实现：可以参考ArrayBlockingQueue的底层实现（锁和同步都行）；

### 进程通讯的方式：消息队列，共享内存，信号量，socket通讯等；

### 用过并发包的哪些类；

### 什么地方用了多线程；

### Excutors可以产生哪些线程池；

### 为什么要用线程池；

### volatile关键字的用法：使多线程中的变量可见；

### 线程的几种状态

## Java内存模型
## 设计模式
### 如何理解观察者模式？
### 列举出你说熟悉的设计模式，并对其中的一种的使用举一个例子。
### 你们产品用到的设计模式
1.访问者模式（backend）

## JVM
## 分布式框架
## redis

### redis和memcache的区别；

### 用redis做过什么；

### redis是如何持久化的：rdb和aof；

### redis集群如何同步；

### redis的数据添加过程是怎样的：哈希槽；

### redis的淘汰策略有哪些；

### redis有哪些数据结构；

## zookeeper
### zookeeper是什么；

### zookeeper哪里用到；

### zookeeper的选主过程；

### zookeeper集群之间如何通讯；

### 你们的zookeeper的节点加密是用的什么方式；

### 分布式锁的实现过程；

## kafka

### 传递保证语义：

* At most once：消息可能会丢，但绝不会重复传递。
* At least once：消息绝不会丢，但可能会重复传递。
* Exactly once： 每条消息只会被传递一次。

### 生产者的“Exactly once”语义方案

当生产者向Kafka发送消息，且正常得到响应的时候，可以确保生产者不会产生重复的消息。但是，如果生产者发送消息后，遇到网络问题，无法获取响应，生产者就无法判断该消息是否成功提交给了Kafka。根据生产者的机制，我们知道，当出现异常时，会进行消息重传，这就可能出现“At least one”语义。为了实现“Exactly once”语义，这里提供两个可选方案：

* 每个分区只有一个生产者写入消息，当出现异常或超时的情况时，生产者就要查询此分区的最后一个消息，用来决定后续操作是消息重传还是继续发送。
* 为每个消息添加一个全局唯一主键，生产者不做其他特殊处理，按照之前分析方式进行重传，由消费者对消息进行去重，实现“Exactly once”语义。

如果业务数据产生消息可以找到合适的字段作为主键，或是有一个全局ID生成器，可以优先考虑选用第二种方案。


### 消费者的“Exactly once”语义方案

为了实现消费者的“Exactly once”语义，在这里提供一种方案，供读者参考：消费者将关闭自动提交offset的功能且不再手动提交offset，这样就不使用Offsets Topic这个内部Topic记录其offset，而是由消费者自己保存offset。这里利用事务的原子性来实现“Exactly once”语义，我们将offset和消息处理结果放在一个事务中，事务执行成功则认为此消息被消费，否则事务回滚需要重新消费。当出现消费者宕机重启或Rebalance操作时，消费者可以从关系型数据库中找到对应的offset，然后调用KafkaConsumer.seek()方法手动设置消费位置，从此offset处开始继续消费。



## dubbo
## TCP/IP
## 算法
## 设计与思想

### 重构过代码没有？说说经验；

### 一千万的用户实时排名如何实现；

### 五万人并发抢票怎么实现；

----
参考链接：
[阿里面试回来，想和Java程序员谈一谈](http://www.jianshu.com/p/5681a1f0aad6)
